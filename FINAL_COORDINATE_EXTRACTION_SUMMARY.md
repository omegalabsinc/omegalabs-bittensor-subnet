# Final Coordinate Extraction Summary

## Testing Overview

We tested three approaches to extract mouse click coordinates from recordings:

1. **Full Video Analysis** (Gemini Pro/Flash on entire video)
2. **Frame-by-Frame Analysis** (Gemini Flash on individual frames)
3. **Ground Truth Validation** (Testing against known coordinates)

## Results Summary

### Method 1: Full Video Analysis
| Model | Steps Extracted | Accuracy | Cost/Video |
|-------|----------------|----------|------------|
| Gemini 2.5 Pro | 25 steps | ¬±20-50px | $0.02 |
| Gemini 2.5 Flash (optimized) | 55 steps | ¬±20-50px | $0.002 |

**Finding**: Prompt optimization eliminated generic coordinates but accuracy remains ¬±20-50px due to AI inferring from context rather than seeing actual cursor.

### Method 2: Frame-by-Frame Analysis
| Test | Detection | Visual Accuracy |
|------|-----------|-----------------|
| Video frames (10 samples) | 7/10 (70%) | ‚úÖ Good (¬±5-10px visually) |

**Finding**: Extracting individual frames and analyzing separately gives much better accuracy when cursor is visible. Crosshairs landed directly on UI elements.

### Method 3: Ground Truth Validation
| Prompt Version | Mean Error | Median Error | Best | Good (< 50px) |
|---------------|------------|--------------|------|---------------|
| **Original** | 318.8px | 70.0px | 25.4px | 2/7 (28.6%) |
| **Improved** | 542.4px | 729.3px | 16.8px | 2/7 (28.6%) |

**Detailed Results (Original Prompt)**:

| Screenshot | Ground Truth | AI Detected | Error | Result |
|-----------|--------------|-------------|-------|--------|
| click_11 | (756, 605) | (778, 592) | **25px** | ‚úÖ Excellent |
| click_12 | (1162, 98) | (1200, 157) | **70px** | ‚ö†Ô∏è Fair |
| click_13 | (1274, 176) | (1254, 204) | **34px** | ‚úÖ Good |
| click_14 | **(41, 117)** | (1139, 118) | **1098px** | ‚ùå Failed (left edge) |
| click_15 | **(41, 110)** | (96, 76) | **65px** | ‚ö†Ô∏è Fair |
| click_16 | **(305, 110)** | (1014, 109) | **709px** | ‚ùå Failed (sidebar) |
| click_17 | **(161, 228)** | (326, 389) | **231px** | ‚ùå Poor (left area) |

## Key Findings

### ‚úÖ What Works:

1. **Center-screen detection** (median: 70px)
   - Clicks in main content area: 25-70px error
   - Acceptable for approximate trajectory visualization
   - Good enough for workflow understanding

2. **Frame-by-frame > Full video**
   - Individual frame analysis: ¬±5-10px (visual validation)
   - Full video analysis: ¬±20-50px
   - 4-5x improvement from breaking video into frames

3. **100% detection rate**
   - AI found cursor in all test images
   - Never falsely reported "no cursor"

### ‚ùå What Doesn't Work:

1. **Left-edge detection** (systematic failure)
   - X-coordinates < 200px: massive errors (700-1000px)
   - Y-coordinates often perfect, X completely wrong
   - Pattern: AI detects something on right side instead

2. **Prompt engineering has limits**
   - More detailed prompts ‚Üí worse results (confused model)
   - Core limitation is perceptual, not instructional
   - Cannot "prompt" AI into seeing what it can't detect

3. **High variance** (unreliable)
   - Best case: 17px error
   - Worst case: 1098px error
   - 43-57% of cases have > 100px error

## Root Cause Analysis

### Why Left-Edge Fails:

1. **Cursor visibility**: White cursor on dark sidebar may be subtle
2. **Visual bias**: AI likely trained on center-focused images
3. **Small targets**: Sidebar icons are smaller, cursor harder to isolate
4. **Context confusion**: AI may be using UI element positions as fallback

### Why Prompt Engineering Failed:

- Adding more instructions ‚Üí model overthinking
- Conflicting guidance ‚Üí worse performance
- Core issue is **perceptual**, not **instructional**
- Model cannot detect what it visually cannot see

## Recommendations

### ‚úÖ Use AI Extraction For:

1. **Approximate trajectory mapping** (70px median acceptable)
2. **Center-screen interactions** (good accuracy)
3. **Workflow understanding** (sequence, not precision)
4. **Research and exploration** (existing video analysis)
5. **Supplementary data** (not primary training source)

**Filtering Strategy**:
```python
# Post-process to remove outliers
valid_steps = [s for s in steps if s.x_coordinate > 0.15]  # Filter left edge
valid_steps = [s for s in steps if calculate_error(s) < 100]  # Filter high error
```

### ‚ùå Do NOT Use AI Extraction For:

1. **Production training data** (too much variance)
2. **Left-edge or sidebar interactions** (systematic failures)
3. **Precise PyAutoGUI commands** (¬±70px too large)
4. **Critical coordinate-dependent tasks**

### üéØ Production Solution:

**Implement Event-Capture Recorder** (still the best approach):

```python
from pynput import mouse
import time

class EventRecorder:
    def record_click(self, x, y, button, pressed):
        if pressed:
            self.events.append({
                "timestamp": time.time(),
                "coordinates": [x / screen_width, y / screen_height],
                "accuracy": "¬±1px"  # Ground truth
            })
```

**Why Event Capture Wins**:
- ‚úÖ ¬±1px accuracy (vs ¬±70-1000px with AI)
- ‚úÖ 100% reliable (no perception issues)
- ‚úÖ Works everywhere (edges, sidebars, all positions)
- ‚úÖ $0 cost after development
- ‚úÖ Real-time capture (no post-processing)

## Cost-Benefit Analysis

| Approach | Accuracy | Cost (10k videos) | Dev Time | Production Ready |
|----------|----------|-------------------|----------|------------------|
| **AI Full Video** | ¬±20-50px | $20-200 | 0 weeks | ‚ùå No |
| **AI Frame-by-Frame** | ¬±70px* | $100 | 0 weeks | ‚ùå No |
| **Event Capture** | ¬±1px | $0 | 4-8 weeks | ‚úÖ Yes |

*70px median for center-screen, 700px+ for edges

## Conclusions

### For Existing Videos:
- ‚úÖ Use frame-by-frame AI extraction with post-filtering
- ‚úÖ Good enough for workflow understanding
- ‚ö†Ô∏è Filter left-edge coordinates (X < 0.15)
- ‚ö†Ô∏è Mark as "approximate" not "precise"

### For New Recordings:
- ‚úÖ **Implement event-capture recorder** (required for production)
- ‚úÖ Priority: HIGH (cannot achieve training quality with AI alone)
- ‚úÖ ROI: Immediate (eliminates all accuracy issues)

### The Reality:
**AI-based coordinate extraction from screenshots/videos has fundamental limitations**. While frame-by-frame analysis works reasonably well for center-screen actions (70px median), it systematically fails for edge interactions and cannot provide training-quality precision.

**For SN24 AgentNet revamp**: Event-capture recorder is not optional - it's necessary for production-quality training data.

---

**Generated**: 2025-11-04
**Models Tested**: Gemini 2.5 Flash, Gemini 2.5 Pro, Gemini 2.0 Flash Exp
**Ground Truth Tests**: 7 screenshots with embedded coordinates
**Verdict**: AI extraction suitable for exploration only, not production training
